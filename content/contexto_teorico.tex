% !TEX root = ../thesis-example.tex
%
\chapter{Contexto teorico}
\label{contexto}

\cleanchapterquote{Un sistema físico macroscópico no puede ser descrito solo en términos de variables mecánicas, la llamada entropía era necesaria}{P. Richmond, J. Mimkes, S. Hutzler}{(2013)}

%\Blindtext[1][1]
%\begin{figure}[htp!]
%\centering
%\includegraphics[scale=0.5]{gfx/chikorita.png}
%\caption{Aqui esta chikorita}
%\end{figure}

La mecánica estadística y la economía son consideradas como dos campos de investigación diferentes, el primero que pertenece a la rama de la física y ciencias naturales, y la segunda a las ciencias sociales.
Sin embargo, a partir del siglo XIX la evolución en la investigación de la economía permitió establecer analogías entre las dos ciencias.
De este modo la economía puede ser estudiada desde el punto de vista de la física estadística.

En este capitulo se presenta al lector los conceptos esenciales para comprender las analogías Física-Economía aplicadas en esta Tesis.
Se introducirán ciertos conceptos de Economía claves para la compresión de esta Tesis.
Del mismo modo, vamos a presentar los conceptos de mecánica estadística que son aplicados. 
En este Capitulo se introducirá al lector al estado del arte de la econofísica y sobretodo, la aplicación del concepto de entropía a la economía.
Finalmente, se presentaran aplicaciones de la econofísica a las finanzas y mercados actuales.

\section{La similitud entre economía y física}


En \textit{Física}, un sistema cerrado conserva la energía,  en \textit{Economía}, un sistema económico cerrado conserva el \textit{dinero}. 
De la anterior analogía se entiende que no hay un flujo externo de dinero, por lo que la cantidad total de dinero se conserva.

La \textit{mecánica estadísitica} estudiada por los físicos, y la economía, tienen en común que ambas estudian grandes ensambles; colecciones de átomos, y agentes económicos, respectivamente.
\citep[][pagina 149]{cottrell_classical_2009}.

\textit{De la anterior analogía, en una colección de átomos se asume que cada uno de ellos posee una energía cinética $\mathit{\varepsilon}_{i} \geqslant 0 $, mientras que en los mercados financieros cada uno de los agentes participantes tiene un recurso llamado dinero el cual no puede ser negativo, es decir  $\mathit{d}_{i} \geqslant 0 $}.(Cottrell, Michelson, Wright, Classical Econophysics, pg.149)

En el contexto de la mecanica estadistica se define un ensamble microcanónico como un conjunto  en el que las características y el comportamiento de los componentes son similares, posee entropía máxima y conservación de energía. Gracias a su naturaleza física, es posible estudiarle como un todo.  

Adicionalmente, en \textit{Física}, a menudo se dice que un sistema se encuentra en equilibrio cuando la energía con que interactúan los componentes es conservada. 


\subsection{Economía neoclásica} 

En los comienzos de la \textit{Econofísica} se encuentran emblemáticos personajes como Adolphe Quétlet(1796-1874), Léon Walras (1834-1910), Vilfredo Pareto (1848-1923), y Adam Smith (1723-1790), quienes ofrecieron un conjunto de ideas que permitieron ampliar la manera en que se estudia la \textit{Economía}.
Una de sus mayores contribuciones es considerar una transaccion como una consecuencia determinista del intercambio de bienes entre dos agentes.
Esta consideracion es innovante con respecto al las corrientes economicas y sociales del siglo XIX (e.g. aspectos sociales,  factores politicos, a distribucipon de la riqueza). 

Esta innovacion permite a la \textit{Econofísica} estudiar los sistemas complejos intrínsecos de la \textit{Economía}. La econofisica entonces considera que sistema complejo esta compuesto de un gran número de \textit{grados de libertad} en diferentes escalas de tiempo \underline{(Richmond Econophysics pg 17)}.

La \textit{Economía neoclásica} puede ser considerafa como la corriente de pensamiento que da lugar a la \textit{Econofísica}. Del mismo modo que Pareto estudió la distribución de la riqueza en el siglo XIX, Adam Smith propuso la descripción de un fenómeno llamado \textit{la mano invisible}. 
Este y otros conceptos de economia pueden ser consultados en el capitulo \ref{glosario}.




\subsection{Retornos} 
%---------------------------------------------------------------------------
%Introducir RETORNOS en el texto
%Se define como  r($\mathit{t_{i}}$) $\equiv $ \textit{x}$(\mathit{t}_{i})$ - \textit{x}($\mathit{t}_{i} - \Delta t$) , donde \textit{x}($\mathit{t}_{i}$ es una secuencia de precios logarítmicos 
Los retornos son usualmente variables de análisis más rentables que el precio perse, por varias razones. La distribución de los retornos es más simétrica y estable en el tiempo que la distribución de los precios en sí. La estructura de los retornos es cercana a estacionaria, mientras que la estructura de los precios observados en el tiempo no lo es (Dacoragna, Et Al, 2001).

El logaritmo de los precios muestra que están normalmente distribuídos, al menos aproximadamente (M.F.M. Osborne, 1959). En este trabajo de tesis se trabaja con los retornos de los registros diarios individuales de cada serie de tiempo financiera, en otras palabras, la ventana temporal entre cada \guillemotleft tick\guillemotright~ es constante y se le conoce como \textit{lag} la cual se denota como $\delta t$. 


Los retornos son expresados como:
\begin{center}
$R_t=P_{t+1}-P_t$~~.
\end{center}
Es decir, el retorno del precio en cuestión ( $R_t$ ) es equivalente al precio individual de su sucesor temporal ( $P_{t+1}$ ) menos el precio del objeto temporal en turno ( $P_t$ ), sin embargo, siguiendo los ideales de Osborne, hay que calcular el logaritmo de los retornos a sabiendas de que los precios se etiquetan como $\mathit{Z_t}$ y son las variables de registro de las mediciones individuales diarias al cierre del mercado, donde \newline $t \in \mathcal{T} = \{\mathit{T_1,T_2,\ldots , T_M}\}$. El logaritmo del precio es:

\begin{center}
$\mathit{Y_{t}} = $ ln $\mathit{Z_{t}}$~~.
\end{center}

Entonces los \textit{retornos logarítmicos} son definidos como: 

\begin{center}
$X_t = $ $\mathit{Y_{t}} - $  $\mathit{Y_{t - 1}}$~~.
\end{center}

Cuya interpretación es la diferencia sucesiva de los logaritmos de los precios  registrados en el tiempo, en otras palabras, la diferencia del logaritmo del precio en turno y su antecesor temporal. Aunque en términos computacionales es mucho más sencillo trabajar con la siguiente expresión que respeta la proposición de Osborne (Frantisek Slanina, 2014): 
\begin{center}
ln $R_t = $ ln $\mathit{P_{t+1}} - $ ln $\mathit{P_{t}}$.
\end{center}%esto fue sacado de la pagina 132 y 133 del libro essentials of econophysics modeling


\section{Analogías Física-Economía} 
\subsection{Ley de Boltzmann-Gibbs y distribución de la probabilidad del dinero (en equilibrio)} 

La \textit{ley de la distribución de la probabilidad de la energía} en la \textit{mecánica estadística}:

\begin{center}
$\mathit{P(\varepsilon)} = $ C $e^{-\varepsilon/\mathit{T}}$,
\end{center}
donde:

$\varepsilon$ es la energía

$C$ es una constante de normalización

$\mathit{T}$ es la temperatura (Wannier,1966) (Cottrell, Michelson, Wright, Classical Econophysics, pg.149)

Dada la similitud de un sistema descrito por la Ley de Boltzmann-Gibbs y las condiciones de un sistema económico cerrado, se puede esta ley a una descripción de la \textit{distribución de la probabilidad del dinero}
(Cottrell, Michelson, Wright, Classical Econophysics, pg.149).


\subsubsection{Distribución de la probabilidad del dinero (en equilibrio)} 


De acuerdo con Cottrel, Michelson y Wright (Cottrell, Michelson, Wright, Classical Econophysics, pg.149) la distribución de la probabilidad del dinero sigue la forma de la \textit{Ley de Boltzmann-Gibbs}


\begin{center}
$\mathit{P(d)} = $ C $e^{-d/\mathit{T}}$,
\end{center}
Donde:

$d$ es el dinero

$C$ es una constante de normalización

$\mathit{T}$ es el promedio de la cantidad de dinero por agente en el sistema económico.

Con base en el artículo \textit{Price variations in a stock market with many agents} por Shubik, Pakzuski y Bak en 1997, la ley de la conservación del dinero establece que el dinero no puede ser manufacturado por agentes del sistema económico pero si puede ser transferido entre ellos. Esta descripción es análoga a la que un sistema conservativo presenta en Física, por ejemplo, cuando en un sistema cerrado sin intercambio de energía con el exterior, los átomos colisionan entre sí. 
\newpage

\subsubsection{Ley de la conservación del dinero.} 

En relación con lo establecido por Shubik, Pakzuski y Bak en 1997 en el artículo ya mencionado, lo que compete en este trabajo de tesis es el resultado de la interacción entre los agentes \textit{i} y \textit{j}. 

Sean \textit{i} y \textit{j} dos agentes que interactúan en el mercado, correspondiéndole a cada uno de ellos una cantidad finita de dinero $d_{i}$ y $d_{j}$ respectivamente, se puede denotar de la siguiente manera: $[d_{i},d_{j}]$. 

Si al llevarse a cabo la interacción entre dos agentes y el intercambio de dinero que llevan a cabo es constante, dicho intercambio se etiqueta como $\Delta d$. El resultado de la interacción de los agentes en cuestión se expresa como:  $[d_{i},d_{j}]$ $\longrightarrow$  $[d'_{i},d'_{j}] = [d_{i} - \Delta d ,d_{j} + \Delta d]$. Dicho lo anterior puede notarse que $d_{i} + d_{j} = d'_{i} + d'_{j}$ lo cual significa que la cantidad total de dinero en la transacción es conservada si no existe un flujo externo de dinero que modifique la cantidad total $d$.

En tales condiciones se asume que la distribución de probabilidad del dinero en equilibrio es invariante pese a fuertes fluctuaciones $\Delta d$ entre los agentes \citep[][pagina 149]{cottrell_classical_2009}.


%Ahora que se ha comprendido que el intercambio de dinero $\Delta d$ entre %los agentes es la interacción elemental para la existencia de la %\textit{Economía}, es momento de entender el funcionamiento de la %\textit{Economía neoclásica} para poder utilizar el concepto de %\textit{caminata aleatoria} mismo que se utiliza para sentar las bases del %concepto de \textit{mercado eficiente}.

como descrito en \citep{Huang2021}.



\subsection{Segunda Ley de la termodinámica y la Segunda Ley de la econofísica} 


%
%Este concepto ha sido discutido por \cite{hernandez-montoya_entropy_2022}.
%El concepto de entropia ha sido largamente estudiado \citep{hernandez-montoya_entropy_2022}.

%El concepto de entropia ha sido largamente estudiado \citep[ver mas informacion en ][]{hernandez-montoya_entropy_2022}.


%Para mas infor ver \citep{hernandez-montoya_entropy_2022,jakimowicz_role_2020,martinez_alisis_nodate}.
Existe una formulación conocida por Kelvin-Planck que dice : \textit{No hay proceso termodinámico en estado constante para el cual el calor es completamente convertido en trabajo} \citep[][pagina 86]{struchtrup}.

Sin embargo, la primera derivación de la segunda ley fue dada por Rudolf Clausius (1822-1888) basada en el argumento de que la dirección en que se transfiere el calor esta restringida y depende estrictamente de las declaraciones en ciclos termodinámicos \citep[][pagina 55]{struchtrup}.  Del desarrollo de la segunda ley por Clausius se tiene que \textit{el calor irá del calor al frío por sí mismo, y no al revés} \citep[][pagina 64]{struchtrup}.

La segunda ley explica la restricción en la eficiencia y la dirección de los procesos, \textit{el calor no puede ser completamente convertido en trabajo} \citep[][pagina 5]{struchtrup}. 

Lo anterior se ha definido en la literatura mediante la siguiente ecuacuón:

\begin{equation}
dS \geqslant \frac{\delta Q}{T},
\end{equation}

donde $\delta$ es la diferencial inexacta del calor $Q [J]$ , entre la temperatura $T [K]$, mientras que $dS$ es el diferencial de la entropía $S$ $\frac{[J]}{[K]}$. Esta relación indica que la entropía es incrementada en procesos espontáneos pero no cambia en equilibrio \citep[][pagina 340]{keszei2011chemical}. 

\subsubsection{Segunda Ley de la econofísica} 

Por analogía con la sección anterior, se llama a $S$ como $S_e$ que es la entropía económica (Georgescu-Roegen, 1971), aunque $S_e$ será una cantidad adimensional, mientras que la constante $\lambda$ es un factor integrante cuya unidad de medida es la moneda según sea el caso \citep[][pagina 166]{richmond} , y en vez de $Q$ se ocupa $M$ que en este caso es el dinero. 

\begin{equation}
dS_e \geqslant \frac{\delta M}{\lambda}
\end{equation}

Es preciso mencionar que en Economía $S_e$ se le llama función de producción. En el presente trabajo de tesis no se determina el factor integrante, aunque existen métodos para obtenerlo, en termodinámica se utiliza la constante de Boltzmann debido a enlace entre temperatura y energía \citep[][pagina 166]{richmond}. 

\subsection{Entropía en la termodinámica y analogía en la econof\'isica} 

Para Clausius en 1865 la entropía es una energía inutilizable que puede provenir de por ejemplo, de un motor de vapor que utiliza combustible, irremediablemente una cantidad de energía no será aprovechada. Adicionalmente sostiene que la energía inutilizable en el universo o cualquier sistema cerrado tiende a incrementar \citep[][pagina 21]{cottrell_classical_2009}. 

La entropía es una cantidad que surge cuando se construye una desigualdad que describe la tendencia al equilibrio  \citep[][pagina 70]{keszei2011chemical}. 

%\subsection{Entropía en la econofísica} 

En el contexto de enofisica, la entropie es la medida de un número total de microestados económicos accesibles o disponibles que pertenecen a un macroestado ( mercado-estado fase "económico"). Aqui la analogía se encuentra en que, la energía mide la probabilidad de que un estado en particular en un espacio fase "económico" sea alcanzado. (pg.200, Richmond, Econophysics) \citep{cottrell_classical_2009}.

\subsection{Entropía en la mecánica estadística} 


Es la medida de un número total de microestados económicos accesibles o disponibles que pertenecen a un macroestado ( mercado-estado fase "económico"), por analogía, la energía mide la probabilidad de que un estado en particular en un espacio fase "económico" sea alcanzado \citep{richmond}.

\subsection{La ecuación de la entropía}

La ecuacion de Boltzman para la entropia esta definida como:

\begin{equation}
	S = -k_B \int p(\Gamma,t) ln p(\Gamma,t) d\Gamma.
	\label{entropyB}
\end{equation}
En esta ecuacion la entropía $S$ es definida para moléculas en un espacio fase determinado  en un macroestado termodinámico.
En la ecuacion \ref{entropyB} $k_B$ es la constante de Boltzmann, $ p(\Gamma,t)$ es la función de densidad de probabilidad en el tiempo de $\Gamma$. $\Gamma$ engloba a las variables de posición y momento del espacio fase \citep[][pagina 13]{richmond}. Cabe mencionar que un macroestado esta relacionado con las variables temperatura, presión, volumen.
 
Por otro lado, en el estudio de microestados discretos contables y accesibles, la ecuación de la entropia es: 
 
 \begin{equation}
 	S = -k_B \Sigma p_r ln p_r.
 \end{equation}  

Donde $p_r$ es la probabilidad de un microestado. 

Otra definicion de la entropia es dada por la ecuacion de Shannon \ref{entropySha}
En este trabajo de Tesis se define como la cantidad de perdida y ganancia de información en un conjunto de datos.

\begin{equation}
	H = - \sum_{n=1}^{n} p_i log(p_i).
	\label{entropySha}
\end{equation}

Donde $p_i$ es la probabilidad del dato en cuestión. 

\section{Aplicaciones de la ecuación de Shannon para la entropía.}

Aunque este trabajo de Tesis no está orientado a la inteligencia artificial (AI por sus siglas en ingles), resulta interesante que la AI aplica el concepto de entropía de la información. 
Por ejemplo \citep{dos2012entropy} utilizan el concepto de entropia para analizar la impureza de una base de datos. 
Ellos estan interesados en analizar las edades de las personas y los alimentos de su preferencia. 
Su metodo aplica una reducción en la entropía antes de procesar la base de datos con un arbol de decisiones. 
Esto les permitió tener una ganancia de información\citep[][]{dos2012entropy}. 
Al hacer una clasificación y etiquetar, obtuvieron los resultados que habían planteado en su hipotesis.

En este punto resulta interesante comprender el alcance que tiene la ecuacion de Shanon, no solamente en la termodinámica. 
Por ejemplo, en la publicación \textit{Entropy Calculation, Information Gain and Decision Tree Learning} del sitio web medium \citep[][]{medium} aplican la entropia para mejorar el modelo de arboles de decisiones.
En inteligencia artificial un arbol de decisiones es frecuentemente utilizado como clasificador de bases de datos.
Calcular la entropia permite tomar los atributos mas importantes de la base de datos para la creacion de un arbol de decisiones asi como medir la homogeneidad de los datos. 
Por consecuencia, puede ayudar a determinar la calidad del arbol de decisiones. 

En otra publicación hecha en el portal tds (towards data science) \citep[][]{tds}, se utiliza el mismo concepto de un árbol de decisiones.
En este caso se tiene como objetivo que el algoritmo de inteligencia artificial determine el impacto de un atributo con respecto otro basado en la cantidad de información que presentan/

La ecuación de la entropía de Shannon no solamente se aplica para árboles de decisión, también se ha utilizado para mostrar que algunos textos poseen más riqueza en su contenido con respecto a un tema. 
Además se menciona que en comparación con las técnicas tradicionales del aprendizaje-máquina.
La aplicacion de la entropia de Shannon disminuye la tasa de falsos positivos en relación con las palabras clave que se refieren a un tema en particular \citep[][]{chan2022knowledge}.   
 
\subsection{La entropia aplicada a la econofisica}

Montoya et al.,
Martinez et al.,


